#!/usr/bin/env python3
"""
üìä API —Ä–æ—É—Ç–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏ –º–µ—Ç—Ä–∏–∫
Production-ready analytics —Å real-time –¥–∞–Ω–Ω—ã–º–∏
"""

import logging
from typing import List, Optional, Dict, Any, Union
from datetime import datetime, timedelta
from decimal import Decimal

from fastapi import APIRouter, Depends, HTTPException, status, Query
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_, desc, asc, func, text
from sqlalchemy.orm import selectinload

from ..models.database import (
    Token, Trade, User, PriceHistory, Analytics, 
    TokenStatus, TradeType, CurveType
)
from ..schemas.requests import PaginationRequest
from ..schemas.responses import (
    AnalyticsResponse, TrendingTokensResponse, MarketStatsResponse,
    VolumeAnalyticsResponse, UserLeaderboardResponse, PriceHistoryResponse,
    TokenPerformanceResponse, PlatformStatsResponse, TokenResponse
)
from ..services.cache import CacheService
from ..core.exceptions import ValidationException, DatabaseException
from ..core.config import settings

logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–Ω–∏–µ —Ä–æ—É—Ç–µ—Ä–∞
router = APIRouter()


# === DEPENDENCY FUNCTIONS ===

async def get_db() -> AsyncSession:
    """Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏ –ë–î"""
    pass


async def get_cache_service() -> CacheService:
    """Dependency –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è Cache —Å–µ—Ä–≤–∏—Å–∞"""
    pass


# === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ===

def _validate_time_period(period: str) -> timedelta:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞"""
    period_mapping = {
        "1h": timedelta(hours=1),
        "24h": timedelta(days=1),
        "7d": timedelta(days=7),
        "30d": timedelta(days=30),
        "90d": timedelta(days=90),
        "1y": timedelta(days=365)
    }
    
    if period not in period_mapping:
        raise ValidationException(f"Invalid period: {period}. Allowed: {list(period_mapping.keys())}")
    
    return period_mapping[period]


async def _get_market_overview(db: AsyncSession) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –æ–±–∑–æ—Ä–∞ —Ä—ã–Ω–∫–∞"""
    
    # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    total_tokens_query = select(func.count(Token.id)).where(
        Token.status == TokenStatus.ACTIVE
    )
    total_tokens = await db.execute(total_tokens_query)
    
    # –û–±—â–∏–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –∑–∞ 24—á
    yesterday = datetime.utcnow() - timedelta(days=1)
    volume_24h_query = select(func.sum(Trade.sol_amount)).where(
        Trade.created_at >= yesterday
    )
    volume_24h = await db.execute(volume_24h_query)
    
    # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤ –∑–∞ 24—á
    trades_24h_query = select(func.count(Trade.id)).where(
        Trade.created_at >= yesterday
    )
    trades_24h = await db.execute(trades_24h_query)
    
    # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    total_users_query = select(func.count(User.id))
    total_users = await db.execute(total_users_query)
    
    # –°—Ä–µ–¥–Ω—è—è —Ä—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è
    avg_market_cap_query = select(func.avg(Token.market_cap)).where(
        and_(
            Token.status == TokenStatus.ACTIVE,
            Token.market_cap > 0
        )
    )
    avg_market_cap = await db.execute(avg_market_cap_query)
    
    return {
        "total_tokens": total_tokens.scalar() or 0,
        "volume_24h": float(volume_24h.scalar() or 0),
        "trades_24h": trades_24h.scalar() or 0,
        "total_users": total_users.scalar() or 0,
        "avg_market_cap": float(avg_market_cap.scalar() or 0)
    }


async def _calculate_price_change(
    db: AsyncSession, 
    token_id: str, 
    period: timedelta
) -> Optional[float]:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã –∑–∞ –ø–µ—Ä–∏–æ–¥"""
    
    try:
        period_start = datetime.utcnow() - period
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞
        start_price_query = select(PriceHistory.price).where(
            and_(
                PriceHistory.token_id == token_id,
                PriceHistory.timestamp >= period_start
            )
        ).order_by(asc(PriceHistory.timestamp)).limit(1)
        
        start_price_result = await db.execute(start_price_query)
        start_price = start_price_result.scalar()
        
        if not start_price:
            return None
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã
        current_price_query = select(PriceHistory.price).where(
            PriceHistory.token_id == token_id
        ).order_by(desc(PriceHistory.timestamp)).limit(1)
        
        current_price_result = await db.execute(current_price_query)
        current_price = current_price_result.scalar()
        
        if not current_price:
            return None
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        price_change = ((float(current_price) - float(start_price)) / float(start_price)) * 100
        return price_change
        
    except Exception as e:
        logger.error(f"Failed to calculate price change: {e}")
        return None


# === ENDPOINTS ===

@router.get("/overview", response_model=MarketStatsResponse)
async def get_market_overview(
    db: AsyncSession = Depends(get_db),
    cache: CacheService = Depends(get_cache_service)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –æ–±–∑–æ—Ä–∞ —Ä—ã–Ω–∫–∞
    
    –í–∫–ª—é—á–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –æ–±—ä–µ–º—ã, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏.
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cache_key = "market_overview"
        cached_data = await cache.get(cache_key, 'analytics')
        
        if cached_data:
            return MarketStatsResponse(**cached_data)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        overview_data = await _get_market_overview(db)
        
        response = MarketStatsResponse(
            **overview_data,
            last_updated=datetime.utcnow()
        )
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 5 –º–∏–Ω—É—Ç
        await cache.set(cache_key, response.dict(), 'analytics', ttl=300)
        
        return response
        
    except Exception as e:
        logger.error(f"Failed to get market overview: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve market overview"
        )


@router.get("/trending/tokens", response_model=TrendingTokensResponse)
async def get_trending_tokens(
    period: str = Query("24h", regex="^(1h|24h|7d)$", description="–í—Ä–µ–º–µ–Ω–Ω–æ–π –ø–µ—Ä–∏–æ–¥"),
    limit: int = Query(20, ge=1, le=100, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤"),
    sort_by: str = Query("volume", regex="^(volume|price_change|trades|market_cap)$"),
    db: AsyncSession = Depends(get_db),
    cache: CacheService = Depends(get_cache_service)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∏–Ω–≥–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    
    –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –æ–±—ä–µ–º—É, –∏–∑–º–µ–Ω–µ–Ω–∏—é —Ü–µ–Ω—ã, –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ—Ä–≥–æ–≤ –∏–ª–∏ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏.
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cache_key = f"trending_tokens:{period}:{limit}:{sort_by}"
        cached_data = await cache.get(cache_key, 'analytics')
        
        if cached_data:
            return TrendingTokensResponse(**cached_data)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–∏–æ–¥–∞
        time_delta = _validate_time_period(period)
        period_start = datetime.utcnow() - time_delta
        
        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = select(Token).where(
            and_(
                Token.status == TokenStatus.ACTIVE,
                Token.market_cap > 0
            )
        ).options(selectinload(Token.creator))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        if sort_by == "volume":
            if period == "1h":
                query = query.order_by(desc(Token.volume_1h))
            elif period == "24h":
                query = query.order_by(desc(Token.volume_24h))
            else:
                query = query.order_by(desc(Token.volume_7d))
        elif sort_by == "market_cap":
            query = query.order_by(desc(Token.market_cap))
        elif sort_by == "price_change":
            # –î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            query = query.order_by(desc(Token.price_change_24h))
        else:  # trades
            query = query.order_by(desc(Token.trades_count))
        
        query = query.limit(limit)
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        result = await db.execute(query)
        tokens = result.scalars().all()
        
        # –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ü–µ–Ω—ã
        trending_tokens = []
        for token in tokens:
            price_change = await _calculate_price_change(db, str(token.id), time_delta)
            
            token_data = {
                "token": TokenResponse.from_orm(token),
                "price_change_percent": price_change,
                "volume_period": getattr(token, f"volume_{period.replace('h', 'h').replace('d', 'd')}", 0),
                "rank": len(trending_tokens) + 1
            }
            trending_tokens.append(token_data)
        
        response = TrendingTokensResponse(
            period=period,
            tokens=trending_tokens,
            last_updated=datetime.utcnow()
        )
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 2 –º–∏–Ω—É—Ç—ã
        await cache.set(cache_key, response.dict(), 'analytics', ttl=120)
        
        return response
        
    except ValidationException:
        raise
    except Exception as e:
        logger.error(f"Failed to get trending tokens: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve trending tokens"
        )


@router.get("/volume", response_model=VolumeAnalyticsResponse)
async def get_volume_analytics(
    period: str = Query("24h", regex="^(1h|24h|7d|30d)$"),
    interval: str = Query("1h", regex="^(5m|15m|1h|4h|1d)$", description="–ò–Ω—Ç–µ—Ä–≤–∞–ª –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏"),
    db: AsyncSession = Depends(get_db),
    cache: CacheService = Depends(get_cache_service)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ –æ–±—ä–µ–º–∞–º —Ç–æ—Ä–≥–æ–≤
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –æ–±—ä–µ–º–æ–≤ —Ç–æ—Ä–≥–æ–≤ —Å –∑–∞–¥–∞–Ω–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º.
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cache_key = f"volume_analytics:{period}:{interval}"
        cached_data = await cache.get(cache_key, 'analytics')
        
        if cached_data:
            return VolumeAnalyticsResponse(**cached_data)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–∏–æ–¥–∞
        time_delta = _validate_time_period(period)
        period_start = datetime.utcnow() - time_delta
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –≤ PostgreSQL —Ñ–æ—Ä–º–∞—Ç–µ
        interval_mapping = {
            "5m": "5 minutes",
            "15m": "15 minutes", 
            "1h": "1 hour",
            "4h": "4 hours",
            "1d": "1 day"
        }
        
        pg_interval = interval_mapping.get(interval, "1 hour")
        
        # SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        volume_query = text("""
            SELECT 
                date_trunc(:interval, created_at) as time_bucket,
                SUM(sol_amount) as volume,
                COUNT(*) as trades_count
            FROM trades 
            WHERE created_at >= :start_time
            GROUP BY time_bucket
            ORDER BY time_bucket
        """)
        
        result = await db.execute(volume_query, {
            "interval": pg_interval,
            "start_time": period_start
        })
        
        volume_data = []
        total_volume = 0
        total_trades = 0
        
        for row in result:
            volume = float(row.volume or 0)
            trades = int(row.trades_count or 0)
            
            volume_data.append({
                "timestamp": row.time_bucket,
                "volume": volume,
                "trades_count": trades
            })
            
            total_volume += volume
            total_trades += trades
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        data_points = len(volume_data)
        avg_volume = total_volume / data_points if data_points > 0 else 0
        avg_trades = total_trades / data_points if data_points > 0 else 0
        
        response = VolumeAnalyticsResponse(
            period=period,
            interval=interval,
            data=volume_data,
            total_volume=total_volume,
            total_trades=total_trades,
            avg_volume_per_interval=avg_volume,
            avg_trades_per_interval=avg_trades,
            last_updated=datetime.utcnow()
        )
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        ttl = 60 if interval in ["5m", "15m"] else 300  # 1-5 –º–∏–Ω—É—Ç
        await cache.set(cache_key, response.dict(), 'analytics', ttl=ttl)
        
        return response
        
    except ValidationException:
        raise
    except Exception as e:
        logger.error(f"Failed to get volume analytics: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve volume analytics"
        )


@router.get("/leaderboard/users", response_model=UserLeaderboardResponse)
async def get_user_leaderboard(
    metric: str = Query("volume", regex="^(volume|pnl|trades|win_rate)$"),
    period: str = Query("30d", regex="^(7d|30d|90d|all)$"),
    limit: int = Query(50, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    cache: CacheService = Depends(get_cache_service)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    
    –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –æ–±—ä–µ–º—É —Ç–æ—Ä–≥–æ–≤, P&L, –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–¥–µ–ª–æ–∫ –∏–ª–∏ win rate.
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cache_key = f"user_leaderboard:{metric}:{period}:{limit}"
        cached_data = await cache.get(cache_key, 'analytics')
        
        if cached_data:
            return UserLeaderboardResponse(**cached_data)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
        if period != "all":
            time_delta = _validate_time_period(period)
            period_start = datetime.utcnow() - time_delta
            time_filter = Trade.created_at >= period_start
        else:
            time_filter = True
        
        # –ó–∞–ø—Ä–æ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç—Ä–∏–∫–∏
        if metric == "volume":
            query = select(
                User.id,
                User.username,
                User.wallet_address,
                User.profile_image_url,
                func.sum(Trade.sol_amount).label('total_volume'),
                func.count(Trade.id).label('trades_count')
            ).join(Trade).where(time_filter).group_by(
                User.id, User.username, User.wallet_address, User.profile_image_url
            ).order_by(desc('total_volume')).limit(limit)
            
        elif metric == "pnl":
            query = select(
                User.id,
                User.username, 
                User.wallet_address,
                User.profile_image_url,
                func.sum(Trade.realized_pnl).label('total_pnl'),
                func.count(Trade.id).label('trades_count')
            ).join(Trade).where(time_filter).group_by(
                User.id, User.username, User.wallet_address, User.profile_image_url
            ).order_by(desc('total_pnl')).limit(limit)
            
        elif metric == "trades":
            query = select(
                User.id,
                User.username,
                User.wallet_address, 
                User.profile_image_url,
                func.count(Trade.id).label('trades_count'),
                func.sum(Trade.sol_amount).label('total_volume')
            ).join(Trade).where(time_filter).group_by(
                User.id, User.username, User.wallet_address, User.profile_image_url
            ).order_by(desc('trades_count')).limit(limit)
            
        else:  # win_rate
            query = select(
                User.id,
                User.username,
                User.wallet_address,
                User.profile_image_url,
                User.win_rate,
                func.count(Trade.id).label('trades_count')
            ).join(Trade).where(time_filter).group_by(
                User.id, User.username, User.wallet_address, User.profile_image_url, User.win_rate
            ).having(func.count(Trade.id) >= 5).order_by(desc(User.win_rate)).limit(limit)
        
        result = await db.execute(query)
        
        leaderboard_data = []
        for i, row in enumerate(result, 1):
            user_data = {
                "rank": i,
                "user_id": str(row.id),
                "username": row.username,
                "wallet_address": row.wallet_address,
                "profile_image_url": row.profile_image_url,
                "metric_value": 0,
                "trades_count": row.trades_count if hasattr(row, 'trades_count') else 0
            }
            
            if metric == "volume":
                user_data["metric_value"] = float(row.total_volume or 0)
            elif metric == "pnl":
                user_data["metric_value"] = float(row.total_pnl or 0)
            elif metric == "trades":
                user_data["metric_value"] = int(row.trades_count or 0)
            else:  # win_rate
                user_data["metric_value"] = float(row.win_rate or 0)
            
            leaderboard_data.append(user_data)
        
        response = UserLeaderboardResponse(
            metric=metric,
            period=period,
            leaderboard=leaderboard_data,
            last_updated=datetime.utcnow()
        )
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 10 –º–∏–Ω—É—Ç
        await cache.set(cache_key, response.dict(), 'analytics', ttl=600)
        
        return response
        
    except ValidationException:
        raise
    except Exception as e:
        logger.error(f"Failed to get user leaderboard: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve user leaderboard"
        )


@router.get("/tokens/{token_id}/performance", response_model=TokenPerformanceResponse)
async def get_token_performance(
    token_id: str,
    period: str = Query("7d", regex="^(1d|7d|30d|90d)$"),
    db: AsyncSession = Depends(get_db),
    cache: CacheService = Depends(get_cache_service)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cache_key = f"token_performance:{token_id}:{period}"
        cached_data = await cache.get(cache_key, 'analytics')
        
        if cached_data:
            return TokenPerformanceResponse(**cached_data)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–∏–æ–¥–∞
        time_delta = _validate_time_period(period)
        period_start = datetime.utcnow() - time_delta
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–∫–µ–Ω–µ
        token_query = select(Token).where(Token.id == token_id)
        token_result = await db.execute(token_query)
        token = token_result.scalar_one_or_none()
        
        if not token:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Token not found"
            )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ—Ä–≥–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥
        trades_stats_query = select(
            func.count(Trade.id).label('total_trades'),
            func.sum(Trade.sol_amount).label('total_volume'),
            func.sum(
                func.case([(Trade.trade_type == TradeType.BUY, Trade.sol_amount)], else_=0)
            ).label('buy_volume'),
            func.sum(
                func.case([(Trade.trade_type == TradeType.SELL, Trade.sol_amount)], else_=0)
            ).label('sell_volume'),
            func.count(func.distinct(Trade.user_id)).label('unique_traders')
        ).where(
            and_(
                Trade.token_id == token_id,
                Trade.created_at >= period_start
            )
        )
        
        trades_stats = await db.execute(trades_stats_query)
        stats_row = trades_stats.first()
        
        # –ò—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω
        price_history_query = select(PriceHistory).where(
            and_(
                PriceHistory.token_id == token_id,
                PriceHistory.timestamp >= period_start
            )
        ).order_by(PriceHistory.timestamp)
        
        price_history_result = await db.execute(price_history_query)
        price_history = price_history_result.scalars().all()
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        price_data = [{"timestamp": ph.timestamp, "price": float(ph.price)} for ph in price_history]
        
        if price_data:
            start_price = price_data[0]["price"]
            current_price = price_data[-1]["price"]
            price_change_percent = ((current_price - start_price) / start_price) * 100
            
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
            prices = [p["price"] for p in price_data]
            high_price = max(prices)
            low_price = min(prices)
        else:
            price_change_percent = 0
            high_price = float(token.current_price)
            low_price = float(token.current_price)
        
        response = TokenPerformanceResponse(
            token_id=token_id,
            token_symbol=token.symbol,
            token_name=token.name,
            period=period,
            current_price=float(token.current_price),
            price_change_percent=price_change_percent,
            high_price=high_price,
            low_price=low_price,
            total_trades=stats_row.total_trades or 0,
            total_volume=float(stats_row.total_volume or 0),
            buy_volume=float(stats_row.buy_volume or 0),
            sell_volume=float(stats_row.sell_volume or 0),
            unique_traders=stats_row.unique_traders or 0,
            price_history=price_data,
            last_updated=datetime.utcnow()
        )
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 5 –º–∏–Ω—É—Ç
        await cache.set(cache_key, response.dict(), 'analytics', ttl=300)
        
        return response
        
    except ValidationException:
        raise
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get token performance: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve token performance"
        )


@router.get("/platform/stats", response_model=PlatformStatsResponse)
async def get_platform_statistics(
    period: str = Query("30d", regex="^(7d|30d|90d|all)$"),
    db: AsyncSession = Depends(get_db),
    cache: CacheService = Depends(get_cache_service)
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cache_key = f"platform_stats:{period}"
        cached_data = await cache.get(cache_key, 'analytics')
        
        if cached_data:
            return PlatformStatsResponse(**cached_data)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
        if period != "all":
            time_delta = _validate_time_period(period)
            period_start = datetime.utcnow() - time_delta
            time_filter = lambda table: table.created_at >= period_start
        else:
            time_filter = lambda table: True
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
        tokens_stats_query = select(
            func.count(Token.id).label('total_tokens'),
            func.count(
                func.case([(Token.is_graduated, 1)], else_=None)
            ).label('graduated_tokens'),
            func.sum(Token.market_cap).label('total_market_cap'),
            func.avg(Token.market_cap).label('avg_market_cap')
        ).where(time_filter(Token))
        
        tokens_stats = await db.execute(tokens_stats_query)
        tokens_row = tokens_stats.first()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        users_stats_query = select(
            func.count(User.id).label('total_users'),
            func.count(
                func.case([(User.tokens_created > 0, 1)], else_=None)
            ).label('token_creators'),
            func.avg(User.reputation_score).label('avg_reputation')
        ).where(time_filter(User))
        
        users_stats = await db.execute(users_stats_query)
        users_row = users_stats.first()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ—Ä–≥–æ–≤
        trades_stats_query = select(
            func.count(Trade.id).label('total_trades'),
            func.sum(Trade.sol_amount).label('total_volume'),
            func.avg(Trade.sol_amount).label('avg_trade_size'),
            func.count(func.distinct(Trade.user_id)).label('active_traders')
        ).where(time_filter(Trade))
        
        trades_stats = await db.execute(trades_stats_query)
        trades_row = trades_stats.first()
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º –∫—Ä–∏–≤—ã—Ö
        curve_distribution_query = select(
            Token.curve_type,
            func.count(Token.id).label('count')
        ).where(time_filter(Token)).group_by(Token.curve_type)
        
        curve_distribution = await db.execute(curve_distribution_query)
        curve_stats = {row.curve_type.value: row.count for row in curve_distribution}
        
        response = PlatformStatsResponse(
            period=period,
            # –¢–æ–∫–µ–Ω—ã
            total_tokens=tokens_row.total_tokens or 0,
            graduated_tokens=tokens_row.graduated_tokens or 0,
            total_market_cap=float(tokens_row.total_market_cap or 0),
            avg_market_cap=float(tokens_row.avg_market_cap or 0),
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
            total_users=users_row.total_users or 0,
            token_creators=users_row.token_creators or 0,
            avg_reputation=float(users_row.avg_reputation or 0),
            # –¢–æ—Ä–≥–∏
            total_trades=trades_row.total_trades or 0,
            total_volume=float(trades_row.total_volume or 0),
            avg_trade_size=float(trades_row.avg_trade_size or 0),
            active_traders=trades_row.active_traders or 0,
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            curve_type_distribution=curve_stats,
            last_updated=datetime.utcnow()
        )
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 15 –º–∏–Ω—É—Ç
        await cache.set(cache_key, response.dict(), 'analytics', ttl=900)
        
        return response
        
    except ValidationException:
        raise
    except Exception as e:
        logger.error(f"Failed to get platform statistics: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve platform statistics"
        )