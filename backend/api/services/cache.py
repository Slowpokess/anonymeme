#!/usr/bin/env python3
"""
üî¥ –°–µ—Ä–≤–∏—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è Anonymeme API
Production-ready Redis integration —Å intelligent caching
"""

import json
import pickle
import logging
from typing import Any, Optional, Dict, List, Union
from datetime import datetime, timedelta
from functools import wraps
import hashlib

import redis.asyncio as redis
from pydantic import BaseModel

from ..core.config import settings
from ..core.exceptions import CacheException, RedisConnectionException

logger = logging.getLogger(__name__)


class CacheStats(BaseModel):
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞"""
    hits: int = 0
    misses: int = 0
    sets: int = 0
    deletes: int = 0
    errors: int = 0
    total_keys: int = 0
    memory_usage_mb: float = 0.0
    hit_rate: float = 0.0


class CacheService:
    """
    Production-ready —Å–µ—Ä–≤–∏—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Å Redis
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—é, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ batch –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.stats = CacheStats()
        
        # –ü—Ä–µ—Ñ–∏–∫—Å—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        self.prefixes = {
            'token': 'token:',
            'user': 'user:',
            'price': 'price:',
            'trade': 'trade:',
            'analytics': 'analytics:',
            'session': 'session:',
            'rate_limit': 'rate:',
            'lock': 'lock:',
        }
        
        # TTL –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
        self.default_ttl = {
            'token': 300,        # 5 –º–∏–Ω—É—Ç
            'user': 600,         # 10 –º–∏–Ω—É—Ç  
            'price': 30,         # 30 —Å–µ–∫—É–Ω–¥
            'trade': 3600,       # 1 —á–∞—Å
            'analytics': 1800,   # 30 –º–∏–Ω—É—Ç
            'session': 86400,    # 1 –¥–µ–Ω—å
            'rate_limit': 3600,  # 1 —á–∞—Å
            'lock': 60,          # 1 –º–∏–Ω—É—Ç–∞
        }
        
        logger.info("Cache service initialized")
    
    def _make_key(self, prefix_type: str, key: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º"""
        prefix = self.prefixes.get(prefix_type, f"{prefix_type}:")
        return f"anonymeme:{prefix}{key}"
    
    def _serialize_value(self, value: Any) -> bytes:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        try:
            if isinstance(value, (str, int, float, bool)):
                return json.dumps(value).encode('utf-8')
            elif isinstance(value, (dict, list)):
                return json.dumps(value, default=str).encode('utf-8')
            else:
                # –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º pickle
                return pickle.dumps(value)
        except Exception as e:
            logger.error(f"Serialization error: {e}")
            raise CacheException(f"Failed to serialize value: {str(e)}")
    
    def _deserialize_value(self, data: bytes, trusted: bool = False) -> Any:
        """
        –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞.
        –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º JSON. –ï—Å–ª–∏ JSON –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ trusted=True,
        –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ pickle.loads (—Å DOCUMENTED justification).
        –ï—Å–ª–∏ trusted=False ‚Äî –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pickle –∏ –≤–µ—Ä–Ω—É—Ç—å None.
        """
        if data is None:
            return None

        # –ü–æ–ø—ã—Ç–∫–∞ JSON –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        try:
            text = data.decode("utf-8")
            return json.loads(text)
        except (UnicodeDecodeError, json.JSONDecodeError):
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ JSON, –≤–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
            logger.debug("–î–∞–Ω–Ω—ã–µ –∫—ç—à–∞ –Ω–µ —è–≤–ª—è—é—Ç—Å—è JSON, –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–ª—å—à–µ (trusted=%s)", trusted)

        # –†–∞–∑—Ä–µ—à–∞–µ–º pickle —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if trusted:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pickle —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω—ã –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö.
                # nosec B301 - pickle –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è trusted=True –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∫—ç—à–∞
                return pickle.loads(data)  # nosec
            except Exception as exc:
                logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ unpickle –¥–∞–Ω–Ω—ã—Ö (trusted=True): %s", exc)
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ unpickle ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None, —Ç.–∫. –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å corrupt data.
                return None
        else:
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ JSON –∏ –Ω–µ trusted ‚Äî –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º pickle (—Ä–∏—Å–∫ RCE).
            logger.warning("–û—Ç–∫–∞–∑ –≤ unpickle –¥–ª—è –Ω–µ–¥–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (trusted=False)")
            return None
    
    async def get(
        self, 
        key: str, 
        prefix_type: str = 'general',
        default: Any = None
    ) -> Any:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞"""
        try:
            cache_key = self._make_key(prefix_type, key)
            data = await self.redis.get(cache_key)
            
            if data is None:
                self.stats.misses += 1
                return default

            self.stats.hits += 1
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ Redis trusted=True
            # —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –Ω–∞—à —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∫—ç—à-—Å–µ—Ä–≤–µ—Ä
            return self._deserialize_value(data, trusted=True)
            
        except Exception as e:
            self.stats.errors += 1
            logger.error(f"Cache get error for key {key}: {e}")
            return default
    
    async def set(
        self,
        key: str,
        value: Any,
        prefix_type: str = 'general',
        ttl: Optional[int] = None,
        if_not_exists: bool = False
    ) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫—ç—à"""
        try:
            cache_key = self._make_key(prefix_type, key)
            serialized_value = self._serialize_value(value)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ TTL
            expire_time = ttl or self.default_ttl.get(prefix_type, 300)
            
            if if_not_exists:
                result = await self.redis.set(
                    cache_key, 
                    serialized_value, 
                    ex=expire_time,
                    nx=True
                )
            else:
                result = await self.redis.set(
                    cache_key, 
                    serialized_value, 
                    ex=expire_time
                )
            
            if result:
                self.stats.sets += 1
            
            return bool(result)
            
        except Exception as e:
            self.stats.errors += 1
            logger.error(f"Cache set error for key {key}: {e}")
            return False
    
    async def delete(self, key: str, prefix_type: str = 'general') -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –∫–ª—é—á–∞ –∏–∑ –∫—ç—à–∞"""
        try:
            cache_key = self._make_key(prefix_type, key)
            result = await self.redis.delete(cache_key)
            
            if result > 0:
                self.stats.deletes += 1
                return True
            return False
            
        except Exception as e:
            self.stats.errors += 1
            logger.error(f"Cache delete error for key {key}: {e}")
            return False
    
    async def exists(self, key: str, prefix_type: str = 'general') -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∫–ª—é—á–∞"""
        try:
            cache_key = self._make_key(prefix_type, key)
            result = await self.redis.exists(cache_key)
            return bool(result)
        except Exception as e:
            logger.error(f"Cache exists error for key {key}: {e}")
            return False
    
    async def expire(self, key: str, ttl: int, prefix_type: str = 'general') -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ TTL –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª—é—á–∞"""
        try:
            cache_key = self._make_key(prefix_type, key)
            result = await self.redis.expire(cache_key, ttl)
            return bool(result)
        except Exception as e:
            logger.error(f"Cache expire error for key {key}: {e}")
            return False
    
    async def increment(
        self, 
        key: str, 
        amount: int = 1, 
        prefix_type: str = 'general',
        ttl: Optional[int] = None
    ) -> int:
        """–ê—Ç–æ–º–∞—Ä–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–∞"""
        try:
            cache_key = self._make_key(prefix_type, key)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pipeline –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
            pipe = self.redis.pipeline()
            pipe.incrby(cache_key, amount)
            
            if ttl:
                pipe.expire(cache_key, ttl)
            
            results = await pipe.execute()
            return results[0]
            
        except Exception as e:
            logger.error(f"Cache increment error for key {key}: {e}")
            return 0
    
    async def get_or_set(
        self,
        key: str,
        factory_func,
        prefix_type: str = 'general',
        ttl: Optional[int] = None,
        *args,
        **kwargs
    ) -> Any:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞ –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∏ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
            cached_value = await self.get(key, prefix_type)
            if cached_value is not None:
                return cached_value
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ, –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
            if asyncio.iscoroutinefunction(factory_func):
                fresh_value = await factory_func(*args, **kwargs)
            else:
                fresh_value = factory_func(*args, **kwargs)
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            await self.set(key, fresh_value, prefix_type, ttl)
            
            return fresh_value
            
        except Exception as e:
            logger.error(f"Cache get_or_set error for key {key}: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—ã—Ç–∞–µ–º—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é
            if asyncio.iscoroutinefunction(factory_func):
                return await factory_func(*args, **kwargs)
            else:
                return factory_func(*args, **kwargs)
    
    async def mget(
        self, 
        keys: List[str], 
        prefix_type: str = 'general'
    ) -> Dict[str, Any]:
        """–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            cache_keys = [self._make_key(prefix_type, key) for key in keys]
            values = await self.redis.mget(cache_keys)
            
            result = {}
            for i, key in enumerate(keys):
                if values[i] is not None:
                    # –î–∞–Ω–Ω—ã–µ –∏–∑ –Ω–∞—à–µ–≥–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ Redis —Å—á–∏—Ç–∞–µ–º trusted
                    result[key] = self._deserialize_value(values[i], trusted=True)
                    self.stats.hits += 1
                else:
                    self.stats.misses += 1
            
            return result
            
        except Exception as e:
            self.stats.errors += 1
            logger.error(f"Cache mget error: {e}")
            return {}
    
    async def mset(
        self, 
        mapping: Dict[str, Any], 
        prefix_type: str = 'general',
        ttl: Optional[int] = None
    ) -> bool:
        """–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π"""
        try:
            pipe = self.redis.pipeline()
            expire_time = ttl or self.default_ttl.get(prefix_type, 300)
            
            for key, value in mapping.items():
                cache_key = self._make_key(prefix_type, key)
                serialized_value = self._serialize_value(value)
                pipe.set(cache_key, serialized_value, ex=expire_time)
            
            results = await pipe.execute()
            success_count = sum(1 for result in results if result)
            self.stats.sets += success_count
            
            return success_count == len(mapping)
            
        except Exception as e:
            self.stats.errors += 1
            logger.error(f"Cache mset error: {e}")
            return False
    
    async def delete_pattern(self, pattern: str, prefix_type: str = 'general') -> int:
        """–£–¥–∞–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–π –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
        try:
            cache_pattern = self._make_key(prefix_type, pattern)
            keys = []
            
            # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–π –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
            async for key in self.redis.scan_iter(match=cache_pattern):
                keys.append(key)
            
            if keys:
                deleted = await self.redis.delete(*keys)
                self.stats.deletes += deleted
                return deleted
            
            return 0
            
        except Exception as e:
            self.stats.errors += 1
            logger.error(f"Cache delete_pattern error: {e}")
            return 0
    
    async def flush_prefix(self, prefix_type: str) -> int:
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫–ª—é—á–µ–π —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º"""
        pattern = f"anonymeme:{self.prefixes[prefix_type]}*"
        return await self.delete_pattern("*", prefix_type)
    
    async def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞"""
        try:
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ Redis
            info = await self.redis.info()
            self.stats.total_keys = info.get('db0', {}).get('keys', 0)
            self.stats.memory_usage_mb = info.get('used_memory', 0) / 1024 / 1024
            
            # –†–∞—Å—á–µ—Ç hit rate
            total_requests = self.stats.hits + self.stats.misses
            if total_requests > 0:
                self.stats.hit_rate = (self.stats.hits / total_requests) * 100
            
            return {
                "hits": self.stats.hits,
                "misses": self.stats.misses,
                "sets": self.stats.sets,
                "deletes": self.stats.deletes,
                "errors": self.stats.errors,
                "total_keys": self.stats.total_keys,
                "memory_usage_mb": round(self.stats.memory_usage_mb, 2),
                "hit_rate": round(self.stats.hit_rate, 2),
                "redis_info": {
                    "connected_clients": info.get('connected_clients', 0),
                    "used_memory_human": info.get('used_memory_human', '0B'),
                    "uptime_in_seconds": info.get('uptime_in_seconds', 0),
                }
            }
            
        except Exception as e:
            logger.error(f"Failed to get cache stats: {e}")
            return self.stats.dict()
    
    # === –°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ú–ï–¢–û–î–´ ===
    
    async def cache_token_data(self, mint_address: str, token_data: Dict[str, Any]) -> bool:
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞"""
        return await self.set(mint_address, token_data, 'token', ttl=300)
    
    async def get_token_data(self, mint_address: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞ –∏–∑ –∫—ç—à–∞"""
        return await self.get(mint_address, 'token')
    
    async def cache_user_profile(self, user_id: str, profile_data: Dict[str, Any]) -> bool:
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return await self.set(user_id, profile_data, 'user', ttl=600)
    
    async def get_user_profile(self, user_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –∫—ç—à–∞"""
        return await self.get(user_id, 'user')
    
    async def cache_price_data(self, mint_address: str, price_data: Dict[str, Any]) -> bool:
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–µ"""
        return await self.set(mint_address, price_data, 'price', ttl=30)
    
    async def get_price_data(self, mint_address: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–µ –∏–∑ –∫—ç—à–∞"""
        return await self.get(mint_address, 'price')
    
    async def rate_limit_check(
        self, 
        identifier: str, 
        limit: int, 
        window: int
    ) -> Tuple[bool, int, int]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ rate limiting
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (allowed, current_count, reset_time)
        """
        try:
            key = f"rate_limit:{identifier}:{window}"
            current_time = int(datetime.utcnow().timestamp())
            window_start = current_time - (current_time % window)
            
            pipe = self.redis.pipeline()
            pipe.zremrangebyscore(key, 0, window_start - window)
            pipe.zcard(key)
            pipe.zadd(key, {str(current_time): current_time})
            pipe.expire(key, window * 2)
            
            results = await pipe.execute()
            current_count = results[1]
            
            allowed = current_count < limit
            reset_time = window_start + window
            
            return allowed, current_count, reset_time
            
        except Exception as e:
            logger.error(f"Rate limit check error: {e}")
            return True, 0, 0  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ä–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–ø—Ä–æ—Å
    
    async def acquire_lock(
        self, 
        lock_key: str, 
        timeout: int = 60,
        identifier: Optional[str] = None
    ) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"""
        try:
            if identifier is None:
                identifier = str(datetime.utcnow().timestamp())
            
            cache_key = self._make_key('lock', lock_key)
            
            # –ü–æ–ø—ã—Ç–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
            acquired = await self.redis.set(
                cache_key, 
                identifier, 
                nx=True, 
                ex=timeout
            )
            
            if acquired:
                return identifier
            return None
            
        except Exception as e:
            logger.error(f"Lock acquisition error: {e}")
            return None
    
    async def release_lock(self, lock_key: str, identifier: str) -> bool:
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"""
        try:
            cache_key = self._make_key('lock', lock_key)
            
            # Lua script –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è
            lua_script = """
            if redis.call("get", KEYS[1]) == ARGV[1] then
                return redis.call("del", KEYS[1])
            else
                return 0
            end
            """
            
            result = await self.redis.eval(lua_script, 1, cache_key, identifier)
            return bool(result)
            
        except Exception as e:
            logger.error(f"Lock release error: {e}")
            return False
    
    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∫—ç—à-—Å–µ—Ä–≤–∏—Å–∞"""
        try:
            # –¢–µ—Å—Ç –∑–∞–ø–∏—Å–∏/—á—Ç–µ–Ω–∏—è
            test_key = f"health_check:{datetime.utcnow().timestamp()}"
            test_value = "health_check_value"
            
            # –ó–∞–ø–∏—Å—å
            write_success = await self.set(test_key, test_value, 'general', ttl=10)
            
            # –ß—Ç–µ–Ω–∏–µ
            read_value = await self.get(test_key, 'general')
            read_success = read_value == test_value
            
            # –£–¥–∞–ª–µ–Ω–∏–µ
            delete_success = await self.delete(test_key, 'general')
            
            # Ping Redis
            ping_result = await self.redis.ping()
            
            return {
                "redis_ping": ping_result,
                "write_test": write_success,
                "read_test": read_success,
                "delete_test": delete_success,
                "overall_health": all([ping_result, write_success, read_success]),
                "stats": await self.get_stats()
            }
            
        except Exception as e:
            logger.error(f"Cache health check failed: {e}")
            return {
                "redis_ping": False,
                "write_test": False,
                "read_test": False,
                "delete_test": False,
                "overall_health": False,
                "error": str(e)
            }


# === –î–ï–ö–û–†–ê–¢–û–†–´ –î–õ–Ø –ö–≠–®–ò–†–û–í–ê–ù–ò–Ø ===

import asyncio


def cache_result(
    key_pattern: str,
    prefix_type: str = 'general',
    ttl: Optional[int] = None,
    cache_none: bool = False
):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π
    
    Args:
        key_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω –∫–ª—é—á–∞, –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å {arg_name} –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        prefix_type: –¢–∏–ø –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–ª—è –∫–ª—é—á–∞
        ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞
        cache_none: –ö—ç—à–∏—Ä–æ–≤–∞—Ç—å –ª–∏ None –∑–Ω–∞—á–µ–Ω–∏—è
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # –ü–æ–ª—É—á–µ–Ω–∏–µ cache service –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å)
            # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø –∫ —Å–µ—Ä–≤–∏—Å—É
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            import inspect
            sig = inspect.signature(func)
            bound_args = sig.bind(*args, **kwargs)
            bound_args.apply_defaults()
            
            # –ó–∞–º–µ–Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –≤ –∫–ª—é—á–µ
            cache_key = key_pattern.format(**bound_args.arguments)
            
            # –•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞ –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            if len(cache_key) > 200:
                cache_key = hashlib.md5(cache_key.encode()).hexdigest()
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø –∫ CacheService instance
            
            return await func(*args, **kwargs)
        
        return wrapper
    return decorator


def invalidate_cache(
    key_patterns: List[str],
    prefix_type: str = 'general'
):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫—ç—à–∞ –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            result = await func(*args, **kwargs)
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–µ–Ω –¥–æ—Å—Ç—É–ø –∫ CacheService instance
            
            return result
        
        return wrapper
    return decorator